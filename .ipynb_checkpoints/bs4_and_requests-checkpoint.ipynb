{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import os\n",
    "import lxml\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "__author__ = \"Mike Zhong\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook will walk through the steps I took to scrape a single table from an html page, the methods used here will be converted into a function and looped over all 16 weeks of the NFL season to generate 16 .csv files. They will then be opened and manipulated using R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mike.zhong\\Dropbox\\dev\\fantasy_analytics\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())\n",
    "wd = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'requests.models.Response'>\n",
      "<Response [200]>\n",
      "<!DOCTYPE html>\n",
      "<html lang=\"en\">\n",
      "<head>\n",
      "<meta charset=\"utf-8\" />\n",
      "<meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\" />\n",
      "<meta name=\"viewport\" content=\"initial-scale=1.0, width=device-width\" />\n",
      "<title>2016 Fantasy Football Statistics | The Football Database</title>\n",
      "<meta name=\"description\" content=\"View week 1 QB,RB,WR,TE fantasy football stats and statistics for the 2016 NFL season. Included are \n"
     ]
    }
   ],
   "source": [
    "my_url = \"http://www.footballdb.com/fantasy-football/index.html?pos=QB%2CRB%2CWR%2CTE&yr=2016&wk=1&rules=1\"\n",
    "\n",
    "html_page = requests.get(my_url)\n",
    "\n",
    "if html_page.status_code != 200:\n",
    "    print(\"Non-200 response code returned, exiting...\")\n",
    "    exit(1)\n",
    "\n",
    "print(type(html_page))\n",
    "print(html_page)\n",
    "print(html_page.text[:400])\n",
    "\n",
    "with open(wd + \"/html/sample_html.html\", 'w+') as fp:\n",
    "    fp.write(html_page.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bs4.BeautifulSoup'>\n",
      "7 <class 'bs4.element.ResultSet'>\n"
     ]
    }
   ],
   "source": [
    "soup = BeautifulSoup(html_page.text, 'lxml')\n",
    "\n",
    "print(type(soup))\n",
    "\n",
    "all_tables = soup.find_all(\"table\")\n",
    "print(len(all_tables), type(all_tables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102 <class 'bs4.element.ResultSet'>\n",
      "19 <class 'bs4.element.ResultSet'>\n"
     ]
    }
   ],
   "source": [
    "table = all_tables[0]\n",
    "trs = table.find_all(\"tr\")\n",
    "print(len(trs), type(trs))\n",
    "\n",
    "tr = trs[1]\n",
    "ths = tr.find_all(\"th\")\n",
    "print(len(ths), type(ths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 <class 'list'>\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "headers = trs[1].text.strip().split('\\n')\n",
    "ncols = len(headers)\n",
    "print(len(headers), type(headers))\n",
    "\n",
    "tds = trs[2].find_all('td')\n",
    "print(len(tds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Player',\n",
       " 'Team',\n",
       " 'Opponent',\n",
       " 'Pts*',\n",
       " 'Att',\n",
       " 'Cmp',\n",
       " 'Yds',\n",
       " 'TD',\n",
       " 'Int',\n",
       " '2Pt',\n",
       " 'Att',\n",
       " 'Yds',\n",
       " 'TD',\n",
       " '2Pt',\n",
       " 'Rec',\n",
       " 'Yds',\n",
       " 'TD',\n",
       " '2Pt',\n",
       " 'FL',\n",
       " 'TD',\n",
       " 'Week']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# modify headers to accomodate my DF structure\n",
    "headers\n",
    "headers.remove('Game')\n",
    "headers.insert(1, 'Team')\n",
    "headers.insert(2, 'Opponent')\n",
    "headers.append('Week')\n",
    "headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Player Team Opponent  Pts* Att Cmp  Yds TD Int 2Pt ...   Yds  \\\n",
      "1           Drew Brees   NO     @OAK  3900  42  28  423  4   0   0 ...     5   \n",
      "2       Jameis Winston   TB      ATL  3300  32  23  281  4   1   0 ...     3   \n",
      "3     Matthew Stafford  DET      IND  3100  39  31  340  3   0   0 ...     5   \n",
      "4           Alex Smith   KC      @SD  3100  48  34  363  2   1   0 ...    15   \n",
      "5    DeAngelo Williams  PIT      WAS  2800   0   0    0  0   0   0 ...   143   \n",
      "6            Matt Ryan  ATL      @TB  2800  39  27  334  2   0   1 ...    10   \n",
      "7   Ben Roethlisberger  PIT      WAS  2800  37  27  300  3   1   0 ...    -2   \n",
      "8        Brandin Cooks   NO     @OAK  2700   0   0    0  0   0   0 ...    11   \n",
      "9        Aaron Rodgers   GB      JAX  2600  34  20  199  2   0   0 ...    16   \n",
      "10        Spencer Ware   KC      @SD  2500   0   0    0  0   0   0 ...    70   \n",
      "11         CJ Anderson  DEN     @CAR  2500   0   0    0  0   0   0 ...    92   \n",
      "12         Eli Manning  NYG      DAL  2400  28  19  207  3   1   0 ...     0   \n",
      "\n",
      "   TD 2Pt Rec  Yds TD 2Pt FL TD Week  \n",
      "1   0   0   0    0  0   0  1  0    1  \n",
      "2   0   0   0    0  0   0  0  0    1  \n",
      "3   0   0   0    0  0   0  0  0    1  \n",
      "4   1   0   0    0  0   0  0  0    1  \n",
      "5   2   0   6   28  0   0  0  0    1  \n",
      "6   0   0   0    0  0   0  0  0    1  \n",
      "7   0   0   0    0  0   0  0  0    1  \n",
      "8   0   0   6  143  2   0  0  0    1  \n",
      "9   1   0   0    0  0   0  0  0    1  \n",
      "10  1   0   7  129  0   0  0  0    1  \n",
      "11  1   0   4   47  1   0  0  0    1  \n",
      "12  0   0   0    0  0   0  0  0    1  \n",
      "\n",
      "[12 rows x 21 columns] <class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "rows = []\n",
    "for tr in trs[2:]:\n",
    "    \n",
    "    row = []\n",
    "    \n",
    "    for td in tr.find_all('td'):\n",
    "        \n",
    "        if len(td) > 0:    \n",
    "            text = td.text.replace(\"\\xa0\", \" \").replace('.', '')\n",
    "            \n",
    "            # get team of player and opposing team, and home/away\n",
    "            bold = td.find('b')\n",
    "            if bold:\n",
    "                row.append(bold.text)\n",
    "                m = re.match(r\"^(.+)@(.+)$\", text)\n",
    "                if m and text.startswith(bold.text):\n",
    "                    row.append(m.groups()[1])\n",
    "                else:\n",
    "                    row.append('@' + m.groups()[0])\n",
    "                continue\n",
    "                \n",
    "            \n",
    "            # parse player name from awful text\n",
    "            m = re.match(r\"^(.+) (.+)\", text)\n",
    "            if m:\n",
    "                name = m.groups()[0][:-1]\n",
    "                name\n",
    "                row.append(name)\n",
    "                continue\n",
    "                \n",
    "            row.append(text)\n",
    "    row.append(1)\n",
    "    rows.append(row)\n",
    "\n",
    "rows\n",
    "my_table = pd.DataFrame(rows, columns=headers)\n",
    "\n",
    "#print(my_table.size)\n",
    "#print(my_table.shape)\n",
    "some_row = my_table[1:13]\n",
    "\n",
    "print(some_row, type(some_row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'C:\\\\Users\\\\mike.zhong\\\\Dropbox\\\\dev\\\\fantasy_analytics/csv/sample_table.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-1848c65eea0e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmy_table\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwd\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"/csv/sample_table.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mC:\\Users\\mike.zhong\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, tupleize_cols, date_format, doublequote, escapechar, decimal)\u001b[0m\n\u001b[1;32m   1401\u001b[0m                                      \u001b[0mdoublequote\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdoublequote\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1402\u001b[0m                                      escapechar=escapechar, decimal=decimal)\n\u001b[0;32m-> 1403\u001b[0;31m         \u001b[0mformatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1404\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1405\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\mike.zhong\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\io\\formats\\format.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1569\u001b[0m             f, handles = _get_handle(self.path_or_buf, self.mode,\n\u001b[1;32m   1570\u001b[0m                                      \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1571\u001b[0;31m                                      compression=self.compression)\n\u001b[0m\u001b[1;32m   1572\u001b[0m             \u001b[0mclose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\mike.zhong\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36m_get_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mis_text\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m             \u001b[1;31m# Python 3 and no explicit encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'replace'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[1;31m# Python 3 and binary mode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'C:\\\\Users\\\\mike.zhong\\\\Dropbox\\\\dev\\\\fantasy_analytics/csv/sample_table.csv'"
     ]
    }
   ],
   "source": [
    "my_table.to_csv(wd + \"/csv/sample_table.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is okay but we want to clean up the 'Player' column, use regex to pull out firs tand last names\n",
    "some_name = 'Drew BreesD Brees'\n",
    "m = re.match(r\"^(.+) (.+)\", some_name)\n",
    "name = m.groups()[0][:-1]\n",
    "name\n",
    "# This is working so I'll plug into the function above and re-run to test it out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
